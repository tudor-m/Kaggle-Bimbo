dtest <- xgb.DMatrix(data = as.matrix(df.test), label=df.test.target, missing = NA)
watchlist <- list(train = dtrain, test = dtest)
log1pEval <- function(preds, dtrain)
{
labels = getinfo(dtrain, "label")
preds[which(preds<0)] = 0
logs = (log1p(preds)-log1p(labels))^2
err = as.numeric(sqrt(mean(logs,na.rm = TRUE)))
return(list(metric="error",value=err))
}
for (min_child_w in 5:5) {
for (max_d in 16) { #22
print(c("max_d: ",max_d))
print(c("fmla= ",fmla_c))
print(c("min_child_weight: ",min_child_w))
nround = 70
param <- list(
#objective           = "multi:softprob", num_class = 4,
objective           = "reg:linear",
booster             = "gbtree",
#booster             = "gblinear",
base_score          = 0.5,
eta                 = 0.025,#0.05, #0.02, # 0.06, #0.01,
max_depth           = max_d, #changed from default of 8
subsample           = 0.5, #0.9, # 0.7
colsample_bytree    = 0.5, # 0.7
#num_parallel_tree   = 2,
nthread = 2,
alpha = 0,    #0.0001,
lambda = 0,
gamma = 0,
scale_pos_weight = 1,
min_child_weight    = min_child_w, #4, #4
eval_metric         = log1pEval,
#eval_metric         = "rmse",
early_stopping_rounds    = 2,
maximize = FALSE
)
if (1==0) {
set.seed(100)
fit.cv.res = xgb.cv(param, dtrain,nrounds = nround,nfold = 5,metrics = "error",showsd = FALSE,prediction = TRUE)
}
set.seed(100)
fit.train = xgb.train(params=param,dtrain,nrounds=nround,print.every.n = 2,maximize = FALSE,watchlist)
if (1==0) {
xgb.plot.importance(xgb.importance(model=fit.train))
head(xgb.importance(model=fit.train))
}
saveDataT(fit.train,DATA_SET,paste(as.character(c("fit.train",".",jBin,".",jj)),collapse = ""))
# PREDICT on test ...
pred_test = predict(fit.train, as.matrix(df.test),missing = NA)
pred_test[which(pred_test<0)] = 0
err_pred_test = errMeasure3(pred_test,df.test.target)
if (VERBOSE == 1){
print(err_pred_test)
}
pred_test_xgb[[jj]] = pred_test
err_pred_test_xgb[[jj]] = err_pred_test
}
}
# FIT on train ...
# random pick 10%:
idxRand = sort(sample(1:nrow(df.train),round(0.1*nrow(df.train))))
dtrain <- xgb.DMatrix(data = as.matrix(df.train[idxRand,]), label=df.train.target[idxRand], missing = NA)
dtest <- xgb.DMatrix(data = as.matrix(df.test), label=df.test.target, missing = NA)
watchlist <- list(train = dtrain, test = dtest)
log1pEval <- function(preds, dtrain)
{
labels = getinfo(dtrain, "label")
preds[which(preds<0)] = 0
logs = (log1p(preds)-log1p(labels))^2
err = as.numeric(sqrt(mean(logs,na.rm = TRUE)))
return(list(metric="error",value=err))
}
for (min_child_w in 5:5) {
for (max_d in 40) { #22
print(c("max_d: ",max_d))
print(c("fmla= ",fmla_c))
print(c("min_child_weight: ",min_child_w))
nround = 70
param <- list(
#objective           = "multi:softprob", num_class = 4,
objective           = "reg:linear",
booster             = "gbtree",
#booster             = "gblinear",
base_score          = 0.5,
eta                 = 0.025,#0.05, #0.02, # 0.06, #0.01,
max_depth           = max_d, #changed from default of 8
subsample           = 0.5, #0.9, # 0.7
colsample_bytree    = 0.5, # 0.7
#num_parallel_tree   = 2,
nthread = 2,
alpha = 0,    #0.0001,
lambda = 0,
gamma = 0,
scale_pos_weight = 1,
min_child_weight    = min_child_w, #4, #4
eval_metric         = log1pEval,
#eval_metric         = "rmse",
early_stopping_rounds    = 2,
maximize = FALSE
)
if (1==0) {
set.seed(100)
fit.cv.res = xgb.cv(param, dtrain,nrounds = nround,nfold = 5,metrics = "error",showsd = FALSE,prediction = TRUE)
}
set.seed(100)
fit.train = xgb.train(params=param,dtrain,nrounds=nround,print.every.n = 2,maximize = FALSE,watchlist)
if (1==0) {
xgb.plot.importance(xgb.importance(model=fit.train))
head(xgb.importance(model=fit.train))
}
saveDataT(fit.train,DATA_SET,paste(as.character(c("fit.train",".",jBin,".",jj)),collapse = ""))
# PREDICT on test ...
pred_test = predict(fit.train, as.matrix(df.test),missing = NA)
pred_test[which(pred_test<0)] = 0
err_pred_test = errMeasure3(pred_test,df.test.target)
if (VERBOSE == 1){
print(err_pred_test)
}
pred_test_xgb[[jj]] = pred_test
err_pred_test_xgb[[jj]] = err_pred_test
}
}
# FIT on train ...
# random pick 10%:
idxRand = sort(sample(1:nrow(df.train),round(0.1*nrow(df.train))))
dtrain <- xgb.DMatrix(data = as.matrix(df.train[idxRand,]), label=df.train.target[idxRand], missing = NA)
dtest <- xgb.DMatrix(data = as.matrix(df.test), label=df.test.target, missing = NA)
watchlist <- list(train = dtrain, test = dtest)
log1pEval <- function(preds, dtrain)
{
labels = getinfo(dtrain, "label")
preds[which(preds<0)] = 0
logs = (log1p(preds)-log1p(labels))^2
err = as.numeric(sqrt(mean(logs,na.rm = TRUE)))
return(list(metric="error",value=err))
}
for (min_child_w in 8:8) {  #5:5
for (max_d in 40) { #22
print(c("max_d: ",max_d))
print(c("fmla= ",fmla_c))
print(c("min_child_weight: ",min_child_w))
nround = 70
param <- list(
#objective           = "multi:softprob", num_class = 4,
objective           = "reg:linear",
booster             = "gbtree",
#booster             = "gblinear",
base_score          = 0.5,
eta                 = 0.025,#0.05, #0.02, # 0.06, #0.01,
max_depth           = max_d, #changed from default of 8
subsample           = 0.5, #0.9, # 0.7
colsample_bytree    = 0.5, # 0.7
#num_parallel_tree   = 2,
nthread = 2,
alpha = 0,    #0.0001,
lambda = 0,
gamma = 0,
scale_pos_weight = 1,
min_child_weight    = min_child_w, #4, #4
eval_metric         = log1pEval,
#eval_metric         = "rmse",
early_stopping_rounds    = 2,
maximize = FALSE
)
if (1==0) {
set.seed(100)
fit.cv.res = xgb.cv(param, dtrain,nrounds = nround,nfold = 5,metrics = "error",showsd = FALSE,prediction = TRUE)
}
set.seed(100)
fit.train = xgb.train(params=param,dtrain,nrounds=nround,print.every.n = 2,maximize = FALSE,watchlist)
if (1==0) {
xgb.plot.importance(xgb.importance(model=fit.train))
head(xgb.importance(model=fit.train))
}
saveDataT(fit.train,DATA_SET,paste(as.character(c("fit.train",".",jBin,".",jj)),collapse = ""))
# PREDICT on test ...
pred_test = predict(fit.train, as.matrix(df.test),missing = NA)
pred_test[which(pred_test<0)] = 0
err_pred_test = errMeasure3(pred_test,df.test.target)
if (VERBOSE == 1){
print(err_pred_test)
}
pred_test_xgb[[jj]] = pred_test
err_pred_test_xgb[[jj]] = err_pred_test
}
}
# FIT on train ...
# random pick 10%:
idxRand = sort(sample(1:nrow(df.train),round(0.4*nrow(df.train))))
dtrain <- xgb.DMatrix(data = as.matrix(df.train[idxRand,]), label=df.train.target[idxRand], missing = NA)
dtest <- xgb.DMatrix(data = as.matrix(df.test), label=df.test.target, missing = NA)
watchlist <- list(train = dtrain, test = dtest)
log1pEval <- function(preds, dtrain)
{
labels = getinfo(dtrain, "label")
preds[which(preds<0)] = 0
logs = (log1p(preds)-log1p(labels))^2
err = as.numeric(sqrt(mean(logs,na.rm = TRUE)))
return(list(metric="error",value=err))
}
for (min_child_w in 8:8) {  #5:5
for (max_d in 40) { #22
print(c("max_d: ",max_d))
print(c("fmla= ",fmla_c))
print(c("min_child_weight: ",min_child_w))
nround = 70
param <- list(
#objective           = "multi:softprob", num_class = 4,
objective           = "reg:linear",
booster             = "gbtree",
#booster             = "gblinear",
base_score          = 0.5,
eta                 = 0.025,#0.05, #0.02, # 0.06, #0.01,
max_depth           = max_d, #changed from default of 8
subsample           = 0.5, #0.9, # 0.7
colsample_bytree    = 0.5, # 0.7
#num_parallel_tree   = 2,
nthread = 2,
alpha = 0,    #0.0001,
lambda = 0,
gamma = 0,
scale_pos_weight = 1,
min_child_weight    = min_child_w, #4, #4
eval_metric         = log1pEval,
#eval_metric         = "rmse",
early_stopping_rounds    = 2,
maximize = FALSE
)
if (1==0) {
set.seed(100)
fit.cv.res = xgb.cv(param, dtrain,nrounds = nround,nfold = 5,metrics = "error",showsd = FALSE,prediction = TRUE)
}
set.seed(100)
fit.train = xgb.train(params=param,dtrain,nrounds=nround,print.every.n = 2,maximize = FALSE,watchlist)
if (1==0) {
xgb.plot.importance(xgb.importance(model=fit.train))
head(xgb.importance(model=fit.train))
}
saveDataT(fit.train,DATA_SET,paste(as.character(c("fit.train",".",jBin,".",jj)),collapse = ""))
# PREDICT on test ...
pred_test = predict(fit.train, as.matrix(df.test),missing = NA)
pred_test[which(pred_test<0)] = 0
err_pred_test = errMeasure3(pred_test,df.test.target)
if (VERBOSE == 1){
print(err_pred_test)
}
pred_test_xgb[[jj]] = pred_test
err_pred_test_xgb[[jj]] = err_pred_test
}
}
# FIT on train ...
# random pick 10%:
idxRand = sort(sample(1:nrow(df.train),round(0.8*nrow(df.train))))
dtrain <- xgb.DMatrix(data = as.matrix(df.train[idxRand,]), label=df.train.target[idxRand], missing = NA)
dtest <- xgb.DMatrix(data = as.matrix(df.test), label=df.test.target, missing = NA)
watchlist <- list(train = dtrain, test = dtest)
log1pEval <- function(preds, dtrain)
{
labels = getinfo(dtrain, "label")
preds[which(preds<0)] = 0
logs = (log1p(preds)-log1p(labels))^2
err = as.numeric(sqrt(mean(logs,na.rm = TRUE)))
return(list(metric="error",value=err))
}
for (min_child_w in 8:8) {  #5:5
for (max_d in 40) { #22
print(c("max_d: ",max_d))
print(c("fmla= ",fmla_c))
print(c("min_child_weight: ",min_child_w))
nround = 70
param <- list(
#objective           = "multi:softprob", num_class = 4,
objective           = "reg:linear",
booster             = "gbtree",
#booster             = "gblinear",
base_score          = 0.5,
eta                 = 0.025,#0.05, #0.02, # 0.06, #0.01,
max_depth           = max_d, #changed from default of 8
subsample           = 0.5, #0.9, # 0.7
colsample_bytree    = 0.5, # 0.7
#num_parallel_tree   = 2,
nthread = 2,
alpha = 0,    #0.0001,
lambda = 0,
gamma = 0,
scale_pos_weight = 1,
min_child_weight    = min_child_w, #4, #4
eval_metric         = log1pEval,
#eval_metric         = "rmse",
early_stopping_rounds    = 2,
maximize = FALSE
)
if (1==0) {
set.seed(100)
fit.cv.res = xgb.cv(param, dtrain,nrounds = nround,nfold = 5,metrics = "error",showsd = FALSE,prediction = TRUE)
}
set.seed(100)
fit.train = xgb.train(params=param,dtrain,nrounds=nround,print.every.n = 2,maximize = FALSE,watchlist)
if (1==0) {
xgb.plot.importance(xgb.importance(model=fit.train))
head(xgb.importance(model=fit.train))
}
saveDataT(fit.train,DATA_SET,paste(as.character(c("fit.train",".",jBin,".",jj)),collapse = ""))
# PREDICT on test ...
pred_test = predict(fit.train, as.matrix(df.test),missing = NA)
pred_test[which(pred_test<0)] = 0
err_pred_test = errMeasure3(pred_test,df.test.target)
if (VERBOSE == 1){
print(err_pred_test)
}
pred_test_xgb[[jj]] = pred_test
err_pred_test_xgb[[jj]] = err_pred_test
}
}
# FIT on train ...
# random pick 10%:
idxRand = sort(sample(1:nrow(df.train),round(0.05*nrow(df.train))))
dtrain <- xgb.DMatrix(data = as.matrix(df.train[idxRand,]), label=df.train.target[idxRand], missing = NA)
dtest <- xgb.DMatrix(data = as.matrix(df.test), label=df.test.target, missing = NA)
watchlist <- list(train = dtrain, test = dtest)
log1pEval <- function(preds, dtrain)
{
labels = getinfo(dtrain, "label")
preds[which(preds<0)] = 0
logs = (log1p(preds)-log1p(labels))^2
err = as.numeric(sqrt(mean(logs,na.rm = TRUE)))
return(list(metric="error",value=err))
}
for (min_child_w in 8:8) {  #5:5
for (max_d in 40) { #22
print(c("max_d: ",max_d))
print(c("fmla= ",fmla_c))
print(c("min_child_weight: ",min_child_w))
nround = 70
param <- list(
#objective           = "multi:softprob", num_class = 4,
objective           = "reg:linear",
booster             = "gbtree",
#booster             = "gblinear",
base_score          = 0.5,
eta                 = 0.025,#0.05, #0.02, # 0.06, #0.01,
max_depth           = max_d, #changed from default of 8
subsample           = 0.5, #0.9, # 0.7
colsample_bytree    = 0.5, # 0.7
#num_parallel_tree   = 2,
nthread = 2,
alpha = 0,    #0.0001,
lambda = 0,
gamma = 0,
scale_pos_weight = 1,
min_child_weight    = min_child_w, #4, #4
eval_metric         = log1pEval,
#eval_metric         = "rmse",
early_stopping_rounds    = 2,
maximize = FALSE
)
if (1==0) {
set.seed(100)
fit.cv.res = xgb.cv(param, dtrain,nrounds = nround,nfold = 5,metrics = "error",showsd = FALSE,prediction = TRUE)
}
set.seed(100)
fit.train = xgb.train(params=param,dtrain,nrounds=nround,print.every.n = 2,maximize = FALSE,watchlist)
if (1==0) {
xgb.plot.importance(xgb.importance(model=fit.train))
head(xgb.importance(model=fit.train))
}
saveDataT(fit.train,DATA_SET,paste(as.character(c("fit.train",".",jBin,".",jj)),collapse = ""))
# PREDICT on test ...
pred_test = predict(fit.train, as.matrix(df.test),missing = NA)
pred_test[which(pred_test<0)] = 0
err_pred_test = errMeasure3(pred_test,df.test.target)
if (VERBOSE == 1){
print(err_pred_test)
}
pred_test_xgb[[jj]] = pred_test
err_pred_test_xgb[[jj]] = err_pred_test
}
}
# FIT on train ...
# random pick 10%:
idxRand = sort(sample(1:nrow(df.train),round(0.01*nrow(df.train))))
dtrain <- xgb.DMatrix(data = as.matrix(df.train[idxRand,]), label=df.train.target[idxRand], missing = NA)
dtest <- xgb.DMatrix(data = as.matrix(df.test), label=df.test.target, missing = NA)
watchlist <- list(train = dtrain, test = dtest)
log1pEval <- function(preds, dtrain)
{
labels = getinfo(dtrain, "label")
preds[which(preds<0)] = 0
logs = (log1p(preds)-log1p(labels))^2
err = as.numeric(sqrt(mean(logs,na.rm = TRUE)))
return(list(metric="error",value=err))
}
for (min_child_w in 8:8) {  #5:5
for (max_d in 40) { #22
print(c("max_d: ",max_d))
print(c("fmla= ",fmla_c))
print(c("min_child_weight: ",min_child_w))
nround = 70
param <- list(
#objective           = "multi:softprob", num_class = 4,
objective           = "reg:linear",
booster             = "gbtree",
#booster             = "gblinear",
base_score          = 0.5,
eta                 = 0.025,#0.05, #0.02, # 0.06, #0.01,
max_depth           = max_d, #changed from default of 8
subsample           = 0.5, #0.9, # 0.7
colsample_bytree    = 0.5, # 0.7
#num_parallel_tree   = 2,
nthread = 2,
alpha = 0,    #0.0001,
lambda = 0,
gamma = 0,
scale_pos_weight = 1,
min_child_weight    = min_child_w, #4, #4
eval_metric         = log1pEval,
#eval_metric         = "rmse",
early_stopping_rounds    = 2,
maximize = FALSE
)
if (1==0) {
set.seed(100)
fit.cv.res = xgb.cv(param, dtrain,nrounds = nround,nfold = 5,metrics = "error",showsd = FALSE,prediction = TRUE)
}
set.seed(100)
fit.train = xgb.train(params=param,dtrain,nrounds=nround,print.every.n = 2,maximize = FALSE,watchlist)
if (1==0) {
xgb.plot.importance(xgb.importance(model=fit.train))
head(xgb.importance(model=fit.train))
}
saveDataT(fit.train,DATA_SET,paste(as.character(c("fit.train",".",jBin,".",jj)),collapse = ""))
# PREDICT on test ...
pred_test = predict(fit.train, as.matrix(df.test),missing = NA)
pred_test[which(pred_test<0)] = 0
err_pred_test = errMeasure3(pred_test,df.test.target)
if (VERBOSE == 1){
print(err_pred_test)
}
pred_test_xgb[[jj]] = pred_test
err_pred_test_xgb[[jj]] = err_pred_test
}
}
# FIT on train ...
# random pick 10%:
idxRand = sort(sample(1:nrow(df.train),round(0.01*nrow(df.train))))
dtrain <- xgb.DMatrix(data = as.matrix(df.train[idxRand,]), label=df.train.target[idxRand], missing = NA)
dtest <- xgb.DMatrix(data = as.matrix(df.test), label=df.test.target, missing = NA)
watchlist <- list(train = dtrain, test = dtest)
log1pEval <- function(preds, dtrain)
{
labels = getinfo(dtrain, "label")
preds[which(preds<0)] = 0
logs = (log1p(preds)-log1p(labels))^2
err = as.numeric(sqrt(mean(logs,na.rm = TRUE)))
return(list(metric="error",value=err))
}
for (min_child_w in 8:8) {  #5:5
for (max_d in 40) { #22
print(c("max_d: ",max_d))
print(c("fmla= ",fmla_c))
print(c("min_child_weight: ",min_child_w))
nround = 70
param <- list(
#objective           = "multi:softprob", num_class = 4,
objective           = "reg:linear",
booster             = "gbtree",
#booster             = "gblinear",
base_score          = 0.5,
eta                 = 0.025,#0.05, #0.02, # 0.06, #0.01,
max_depth           = max_d, #changed from default of 8
subsample           = 0.5, #0.9, # 0.7
colsample_bytree    = 0.5, # 0.7
#num_parallel_tree   = 2,
nthread = 2,
alpha = 0,    #0.0001,
lambda = 0,
gamma = 0,
scale_pos_weight = 1,
min_child_weight    = min_child_w, #4, #4
eval_metric         = log1pEval,
#eval_metric         = "rmse",
early_stopping_rounds    = 2,
maximize = FALSE
)
if (1==0) {
set.seed(100)
fit.cv.res = xgb.cv(param, dtrain,nrounds = nround,nfold = 5,metrics = "error",showsd = FALSE,prediction = TRUE)
}
set.seed(100)
fit.train = xgb.train(params=param,dtrain,nrounds=nround,print.every.n = 2,maximize = FALSE,watchlist)
if (1==0) {
xgb.plot.importance(xgb.importance(model=fit.train))
head(xgb.importance(model=fit.train))
}
saveDataT(fit.train,DATA_SET,paste(as.character(c("fit.train",".",jBin,".",jj)),collapse = ""))
# PREDICT on test ...
pred_test = predict(fit.train, as.matrix(df.test),missing = NA)
pred_test[which(pred_test<0)] = 0
err_pred_test = errMeasure3(pred_test,df.test.target)
if (VERBOSE == 1){
print(err_pred_test)
}
pred_test_xgb[[jj]] = pred_test
err_pred_test_xgb[[jj]] = err_pred_test
}
}
source('~/Projects/Kaggle/Kaggle-Bimbo/R/assmbl.wip.002-cv-total.R')
source('~/Projects/Kaggle/Kaggle-Bimbo/R/LoadAndCombine.R')
source('~/Projects/Kaggle/Kaggle-Bimbo/R/LoadAndCombine.R')
305/2003
